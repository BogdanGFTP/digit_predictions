{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BogdanGFTP/digit_predictions/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FjGMtCqT_FT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a31e57ec-85b7-4b41-e6a6-87d84f0dc371"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xntCSxI6_Qi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
        "MODEL_FILE = \"model.h5\"\n",
        "KAGGLE_SUBMISSION_FILE = \"kaggle_submission.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cu03AK0N_2Ue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "VERBOSITY = 1\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512\n",
        "CLASSES = 10\n",
        "CHANNELS = 1\n",
        "IMAGE_SIZE = 28\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
        "VALIDATION_RATIO = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9bcStAe_7mP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = \"drive/My Drive/MNIST/\"\n",
        "train = pd.read_csv(path + \"train.csv\")\n",
        "test = pd.read_csv(path + \"test.csv\")\n",
        "\n",
        "y = train[\"label\"]\n",
        "x = train.drop(labels = [\"label\"], axis = 1) \n",
        "\n",
        "# Reshape data\n",
        "x = x.values.reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS)\n",
        "test = test.values.reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS)\n",
        "\n",
        "# One-Hot encoding\n",
        "y = to_categorical(y, num_classes=CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ow7U_xFaIF7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ffdcc75-5e56-4eb6-99d9-4a20b5a9a4a4"
      },
      "cell_type": "code",
      "source": [
        "import gc; gc.enable()\n",
        "gc.collect()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "wU_xzlzxAEoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prepare training/validation sets\n",
        "x_training, x_validation, y_training, y_validation = train_test_split(x,\n",
        "                                                                      y,\n",
        "                                                                      test_size=VALIDATION_RATIO,\n",
        "                                                                      shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-9D65XgAK7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "fd05f54d-1bca-4619-832b-99a6ef81e7e2"
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
        "x = Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu')(inp)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu')(x)\n",
        "x = Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu')(x)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(8192, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(8192, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inp, output)\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8192)              25698304  \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 8192)              67117056  \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                81930     \n",
            "=================================================================\n",
            "Total params: 92,953,546\n",
            "Trainable params: 92,953,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DNa-5xRBt60",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.00001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRChk4o7CzaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "data_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range=1,\n",
        "                                    zoom_range=0.1, \n",
        "                                    width_shift_range=0.05,\n",
        "                                    height_shift_range=0.05)\n",
        "data_generator.fit(x_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ck70-JzJQJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b933e0bc-8a71-4470-a2eb-7968c436dff3"
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "4i5keKZUC02b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3437
        },
        "outputId": "496c3781-0d10-407a-fa93-9e61a2244a9f"
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "history = model.fit_generator(data_generator.flow(x_training,\n",
        "                                                  y_training,\n",
        "                                                  batch_size=BATCH_SIZE),\n",
        "                              epochs=EPOCHS,\n",
        "                              validation_data=(x_validation, y_validation),\n",
        "                              verbose=VERBOSITY,\n",
        "                              steps_per_epoch=x_training.shape[0] // BATCH_SIZE,\n",
        "                              callbacks=[CSVLogger(TRAINING_LOGS_FILE,\n",
        "                                                   append=False,\n",
        "                                                   separator=\";\")])\n",
        "model.save_weights(MODEL_FILE)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "73/73 [==============================] - 23s 314ms/step - loss: 1.1336 - acc: 0.6198 - val_loss: 1.7201 - val_acc: 0.8902\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 18s 240ms/step - loss: 0.4965 - acc: 0.8378 - val_loss: 0.8771 - val_acc: 0.9450\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.3200 - acc: 0.8955 - val_loss: 0.6787 - val_acc: 0.9569\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.2245 - acc: 0.9275 - val_loss: 0.5300 - val_acc: 0.9664\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.1837 - acc: 0.9414 - val_loss: 0.6064 - val_acc: 0.9624\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.1504 - acc: 0.9518 - val_loss: 0.3607 - val_acc: 0.9776\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.1357 - acc: 0.9577 - val_loss: 0.3208 - val_acc: 0.9798\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.1199 - acc: 0.9613 - val_loss: 0.2924 - val_acc: 0.9817\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.1061 - acc: 0.9664 - val_loss: 0.2976 - val_acc: 0.9812\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.1003 - acc: 0.9687 - val_loss: 0.2360 - val_acc: 0.9850\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0912 - acc: 0.9716 - val_loss: 0.2661 - val_acc: 0.9831\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0887 - acc: 0.9721 - val_loss: 0.2391 - val_acc: 0.9850\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0820 - acc: 0.9740 - val_loss: 0.1996 - val_acc: 0.9876\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0742 - acc: 0.9755 - val_loss: 0.2046 - val_acc: 0.9871\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0715 - acc: 0.9772 - val_loss: 0.2068 - val_acc: 0.9871\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0693 - acc: 0.9773 - val_loss: 0.1990 - val_acc: 0.9874\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0665 - acc: 0.9793 - val_loss: 0.1958 - val_acc: 0.9879\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0650 - acc: 0.9793 - val_loss: 0.2405 - val_acc: 0.9840\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0615 - acc: 0.9803 - val_loss: 0.1844 - val_acc: 0.9883\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0611 - acc: 0.9809 - val_loss: 0.1772 - val_acc: 0.9888\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0574 - acc: 0.9823 - val_loss: 0.2184 - val_acc: 0.9862\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0610 - acc: 0.9812 - val_loss: 0.1889 - val_acc: 0.9881\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0555 - acc: 0.9824 - val_loss: 0.1765 - val_acc: 0.9890\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0540 - acc: 0.9838 - val_loss: 0.1677 - val_acc: 0.9893\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0507 - acc: 0.9837 - val_loss: 0.1573 - val_acc: 0.9902\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0504 - acc: 0.9839 - val_loss: 0.1689 - val_acc: 0.9895\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0508 - acc: 0.9843 - val_loss: 0.1724 - val_acc: 0.9893\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0461 - acc: 0.9850 - val_loss: 0.1420 - val_acc: 0.9912\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0480 - acc: 0.9843 - val_loss: 0.1765 - val_acc: 0.9890\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0467 - acc: 0.9859 - val_loss: 0.1652 - val_acc: 0.9898\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0466 - acc: 0.9856 - val_loss: 0.1650 - val_acc: 0.9898\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0436 - acc: 0.9859 - val_loss: 0.1636 - val_acc: 0.9898\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0463 - acc: 0.9850 - val_loss: 0.1733 - val_acc: 0.9890\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0435 - acc: 0.9861 - val_loss: 0.1436 - val_acc: 0.9910\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0410 - acc: 0.9874 - val_loss: 0.1458 - val_acc: 0.9910\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0415 - acc: 0.9875 - val_loss: 0.1305 - val_acc: 0.9919\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0423 - acc: 0.9867 - val_loss: 0.1343 - val_acc: 0.9917\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0399 - acc: 0.9874 - val_loss: 0.1252 - val_acc: 0.9921\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0380 - acc: 0.9878 - val_loss: 0.1423 - val_acc: 0.9910\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0390 - acc: 0.9884 - val_loss: 0.1650 - val_acc: 0.9898\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0380 - acc: 0.9881 - val_loss: 0.1458 - val_acc: 0.9910\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0368 - acc: 0.9880 - val_loss: 0.1497 - val_acc: 0.9907\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0360 - acc: 0.9885 - val_loss: 0.1344 - val_acc: 0.9917\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0360 - acc: 0.9887 - val_loss: 0.1415 - val_acc: 0.9912\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 17s 238ms/step - loss: 0.0385 - acc: 0.9879 - val_loss: 0.1573 - val_acc: 0.9902\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0345 - acc: 0.9887 - val_loss: 0.1533 - val_acc: 0.9905\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0353 - acc: 0.9889 - val_loss: 0.1499 - val_acc: 0.9905\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0322 - acc: 0.9900 - val_loss: 0.1612 - val_acc: 0.9900\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0327 - acc: 0.9896 - val_loss: 0.1458 - val_acc: 0.9910\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0329 - acc: 0.9895 - val_loss: 0.1403 - val_acc: 0.9912\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0358 - acc: 0.9887 - val_loss: 0.1573 - val_acc: 0.9902\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0338 - acc: 0.9897 - val_loss: 0.1759 - val_acc: 0.9890\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0333 - acc: 0.9892 - val_loss: 0.1535 - val_acc: 0.9905\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0317 - acc: 0.9894 - val_loss: 0.1501 - val_acc: 0.9905\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0316 - acc: 0.9898 - val_loss: 0.1650 - val_acc: 0.9898\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0315 - acc: 0.9898 - val_loss: 0.1485 - val_acc: 0.9907\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0308 - acc: 0.9905 - val_loss: 0.1479 - val_acc: 0.9907\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0315 - acc: 0.9903 - val_loss: 0.1650 - val_acc: 0.9898\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.1543 - val_acc: 0.9902\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0309 - acc: 0.9903 - val_loss: 0.1208 - val_acc: 0.9924\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0288 - acc: 0.9904 - val_loss: 0.1420 - val_acc: 0.9912\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0289 - acc: 0.9911 - val_loss: 0.1727 - val_acc: 0.9893\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0296 - acc: 0.9903 - val_loss: 0.1537 - val_acc: 0.9902\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0288 - acc: 0.9907 - val_loss: 0.1846 - val_acc: 0.9881\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0274 - acc: 0.9909 - val_loss: 0.1535 - val_acc: 0.9905\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0283 - acc: 0.9906 - val_loss: 0.1305 - val_acc: 0.9919\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0280 - acc: 0.9914 - val_loss: 0.1360 - val_acc: 0.9914\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0274 - acc: 0.9914 - val_loss: 0.1305 - val_acc: 0.9919\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.1306 - val_acc: 0.9919\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0280 - acc: 0.9907 - val_loss: 0.1561 - val_acc: 0.9902\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0265 - acc: 0.9920 - val_loss: 0.1421 - val_acc: 0.9910\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0281 - acc: 0.9912 - val_loss: 0.1427 - val_acc: 0.9907\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0269 - acc: 0.9917 - val_loss: 0.1351 - val_acc: 0.9914\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0273 - acc: 0.9909 - val_loss: 0.2073 - val_acc: 0.9871\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0265 - acc: 0.9920 - val_loss: 0.1381 - val_acc: 0.9912\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0288 - acc: 0.9907 - val_loss: 0.1295 - val_acc: 0.9919\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0266 - acc: 0.9916 - val_loss: 0.1411 - val_acc: 0.9912\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0274 - acc: 0.9921 - val_loss: 0.1612 - val_acc: 0.9900\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.1901 - val_acc: 0.9881\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0291 - acc: 0.9904 - val_loss: 0.1300 - val_acc: 0.9919\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.1329 - val_acc: 0.9917\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0239 - acc: 0.9925 - val_loss: 0.1480 - val_acc: 0.9907\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.1305 - val_acc: 0.9919\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.1382 - val_acc: 0.9914\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0264 - acc: 0.9916 - val_loss: 0.1382 - val_acc: 0.9914\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.1729 - val_acc: 0.9890\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0255 - acc: 0.9923 - val_loss: 0.1804 - val_acc: 0.9888\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0268 - acc: 0.9924 - val_loss: 0.1726 - val_acc: 0.9893\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0230 - acc: 0.9924 - val_loss: 0.1634 - val_acc: 0.9898\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.1330 - val_acc: 0.9917\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0254 - acc: 0.9920 - val_loss: 0.1585 - val_acc: 0.9900\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0235 - acc: 0.9926 - val_loss: 0.1344 - val_acc: 0.9917\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0236 - acc: 0.9923 - val_loss: 0.1508 - val_acc: 0.9905\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0252 - acc: 0.9918 - val_loss: 0.1612 - val_acc: 0.9900\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0249 - acc: 0.9920 - val_loss: 0.1266 - val_acc: 0.9921\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0239 - acc: 0.9925 - val_loss: 0.1650 - val_acc: 0.9898\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.1316 - val_acc: 0.9917\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.1427 - val_acc: 0.9910\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 17s 236ms/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.1420 - val_acc: 0.9912\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.0237 - acc: 0.9929 - val_loss: 0.1881 - val_acc: 0.9883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LQOgMPKSC8VM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19a16ac8-fc9e-46a4-d277-7000be1d5de3"
      },
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "predictions = model.predict(test, verbose=1)\n",
        "results = np.argmax(predictions,axis = 1)\n",
        "pd.DataFrame({\"ImageId\":list(range(1,len(results)+1)),\n",
        "              \"Label\":results}).to_csv(KAGGLE_SUBMISSION_FILE,\n",
        "                                           index=False,\n",
        "                                           header=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000/28000 [==============================] - 9s 315us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}