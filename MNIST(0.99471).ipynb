{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BogdanGFTP/digit_predictions/blob/master/MNIST(0.99471).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FjGMtCqT_FT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "c7e88d76-2e48-46ee-f94f-3b0a958ce442"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xntCSxI6_Qi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34bcaae8-4765-4de1-c760-e652ef5837c8"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, Callback\n",
        "from keras import backend as K\n",
        "\n",
        "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
        "MODEL_FILE = \"model.h5\"\n",
        "KAGGLE_SUBMISSION_FILE = \"kaggle_submission.csv\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cu03AK0N_2Ue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "VERBOSITY = 1\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512\n",
        "CLASSES = 10\n",
        "CHANNELS = 1\n",
        "IMAGE_SIZE = 28\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
        "VALIDATION_RATIO = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vt88XBVINAr1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Learning rate finder\n",
        "\n",
        "class LR_Finder(Callback):\n",
        "    \n",
        "    def __init__(self, start_lr=1e-5, end_lr=10, step_size=None, beta=.98):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.start_lr = start_lr\n",
        "        self.end_lr = end_lr\n",
        "        self.step_size = step_size\n",
        "        self.beta = beta\n",
        "        self.lr_mult = (end_lr/start_lr)**(1/step_size)\n",
        "        \n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.best_loss = 1e9\n",
        "        self.avg_loss = 0\n",
        "        self.losses, self.smoothed_losses, self.lrs, self.iterations = [], [], [], []\n",
        "        self.iteration = 0\n",
        "        logs = logs or {}\n",
        "        K.set_value(self.model.optimizer.lr, self.start_lr)\n",
        "        \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        loss = logs.get('loss')\n",
        "        self.iteration += 1\n",
        "        \n",
        "        self.avg_loss = self.beta * self.avg_loss + (1 - self.beta) * loss\n",
        "        smoothed_loss = self.avg_loss / (1 - self.beta**self.iteration)\n",
        "        \n",
        "        # Check if the loss is not exploding\n",
        "        if self.iteration>1 and smoothed_loss > self.best_loss * 4:\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if smoothed_loss < self.best_loss or self.iteration==1:\n",
        "            self.best_loss = smoothed_loss\n",
        "        \n",
        "        lr = self.start_lr * (self.lr_mult**self.iteration)\n",
        "        \n",
        "        self.losses.append(loss)\n",
        "        self.smoothed_losses.append(smoothed_loss)\n",
        "        self.lrs.append(lr)\n",
        "        self.iterations.append(self.iteration)\n",
        "        \n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, lr)  \n",
        "        \n",
        "    def plot_lr(self):\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Learning rate')\n",
        "        plt.plot(self.iterations, self.lrs)\n",
        "        \n",
        "    def plot(self, n_skip=10):\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Learning rate (log scale)')\n",
        "        plt.plot(self.lrs[n_skip:-5], self.losses[n_skip:-5])\n",
        "        plt.xscale('log')\n",
        "        \n",
        "    def plot_smoothed_loss(self, n_skip=10):\n",
        "        plt.ylabel('Smoothed Losses')\n",
        "        plt.xlabel('Learning rate (log scale)')\n",
        "        plt.plot(self.lrs[n_skip:-5], self.smoothed_losses[n_skip:-5])\n",
        "        plt.xscale('log')\n",
        "        \n",
        "    def plot_loss(self):\n",
        "        plt.ylabel('Losses')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.plot(self.iterations[10:], self.losses[10:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9bcStAe_7mP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = \"drive/My Drive/MNIST/\"\n",
        "train = pd.read_csv(path + \"train.csv\")\n",
        "test = pd.read_csv(path + \"test.csv\")\n",
        "\n",
        "y = train[\"label\"]\n",
        "x = train.drop(labels = [\"label\"], axis = 1) \n",
        "\n",
        "# Reshape data\n",
        "x = x.values.reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS)\n",
        "test = test.values.reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS)\n",
        "\n",
        "# One-Hot encoding\n",
        "y = to_categorical(y, num_classes=CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ow7U_xFaIF7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9545ec6-4035-4335-f833-d326c14c9dd3"
      },
      "cell_type": "code",
      "source": [
        "import gc; gc.enable()\n",
        "gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "wU_xzlzxAEoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prepare training/validation sets\n",
        "x_training, x_validation, y_training, y_validation = train_test_split(x,\n",
        "                                                                      y,\n",
        "                                                                      test_size=VALIDATION_RATIO,\n",
        "                                                                      shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYtAN_C2RvdF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-9D65XgAK7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "09dadc72-f0f8-41ba-82ee-5133fae32d56"
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
        "x = Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu')(inp)\n",
        "x = MaxPool2D(pool_size=(2,2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu')(x)\n",
        "x = Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu')(x)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(8192, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(8192, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inp, output)\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8192)              25698304  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8192)              67117056  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                81930     \n",
            "=================================================================\n",
            "Total params: 92,953,546\n",
            "Trainable params: 92,953,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iRChk4o7CzaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "data_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range=1,\n",
        "                                    zoom_range=0.1, \n",
        "                                    width_shift_range=0.05,\n",
        "                                    height_shift_range=0.05)\n",
        "data_generator.fit(x_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ck70-JzJQJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4889e036-13aa-476f-d141-11e7a3232b88"
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "9DNa-5xRBt60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "43d7600d-11d7-46eb-bdb7-33161c1063fe"
      },
      "cell_type": "code",
      "source": [
        "lrf = LR_Finder(start_lr=1e-6, end_lr=1e-1, step_size=50)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='ADAM', metrics=['accuracy'])\n",
        "model.fit_generator(generator=data_generator.flow(x_training, y_training, batch_size=BATCH_SIZE),\n",
        "                    epochs=1,\n",
        "                    steps_per_epoch=x_training.shape[0] // BATCH_SIZE,\n",
        "                    callbacks=[lrf])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "73/73 [==============================] - 20s 273ms/step - loss: 4.8804 - acc: 0.1842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe1ce4cfc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Vy3RArwTNmuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2e605a0c-1ebb-418c-ffae-52bdf654670a"
      },
      "cell_type": "code",
      "source": [
        "lrf.plot_lr()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGaSiICIig1QURERk0P8HoWmxBv3wc9kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe1cdf139e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cBnIOMRrNqlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "03bef65a-8973-483b-babe-4e8b9b3f50d6"
      },
      "cell_type": "code",
      "source": [
        "lrf.plot_smoothed_loss()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAENCAYAAAAPAhLDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEQFQUREABUEERGJqCCIiAgA/z8ZGl4DNlnPoAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe1ce470080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4i5keKZUC02b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3437
        },
        "outputId": "9a2c39b2-aad9-4a7d-cec3-ae78b4bb0585"
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "model.compile(optimizer=Adam(lr=1e-4, epsilon=1e-08, decay=0.00001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit_generator(data_generator.flow(x_training,\n",
        "                                                  y_training,\n",
        "                                                  batch_size=BATCH_SIZE),\n",
        "                              epochs=EPOCHS,\n",
        "                              validation_data=(x_validation, y_validation),\n",
        "                              verbose=VERBOSITY,\n",
        "                              steps_per_epoch=x_training.shape[0] // BATCH_SIZE,\n",
        "                              callbacks=[CSVLogger(TRAINING_LOGS_FILE,\n",
        "                                                   append=False,\n",
        "                                                   separator=\";\")])\n",
        "model.save_weights(MODEL_FILE)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "73/73 [==============================] - 21s 290ms/step - loss: 1.2180 - acc: 0.6080 - val_loss: 1.5011 - val_acc: 0.9043\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 18s 252ms/step - loss: 0.5257 - acc: 0.8323 - val_loss: 0.8684 - val_acc: 0.9450\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.3140 - acc: 0.9014 - val_loss: 0.5555 - val_acc: 0.9648\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.2257 - acc: 0.9300 - val_loss: 0.3624 - val_acc: 0.9769\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.1846 - acc: 0.9415 - val_loss: 0.3493 - val_acc: 0.9776\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.1530 - acc: 0.9513 - val_loss: 0.2665 - val_acc: 0.9831\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.1400 - acc: 0.9548 - val_loss: 0.2631 - val_acc: 0.9836\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 18s 251ms/step - loss: 0.1251 - acc: 0.9600 - val_loss: 0.2248 - val_acc: 0.9860\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.1178 - acc: 0.9620 - val_loss: 0.2258 - val_acc: 0.9860\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.1069 - acc: 0.9661 - val_loss: 0.1999 - val_acc: 0.9874\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0996 - acc: 0.9674 - val_loss: 0.1972 - val_acc: 0.9874\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0941 - acc: 0.9694 - val_loss: 0.1848 - val_acc: 0.9883\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 18s 251ms/step - loss: 0.0884 - acc: 0.9713 - val_loss: 0.1845 - val_acc: 0.9883\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 18s 251ms/step - loss: 0.0868 - acc: 0.9717 - val_loss: 0.1854 - val_acc: 0.9883\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0839 - acc: 0.9732 - val_loss: 0.1677 - val_acc: 0.9895\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0741 - acc: 0.9760 - val_loss: 0.1804 - val_acc: 0.9888\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0732 - acc: 0.9759 - val_loss: 0.1635 - val_acc: 0.9895\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0718 - acc: 0.9776 - val_loss: 0.1509 - val_acc: 0.9905\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0659 - acc: 0.9777 - val_loss: 0.1343 - val_acc: 0.9917\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0668 - acc: 0.9782 - val_loss: 0.1266 - val_acc: 0.9921\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0636 - acc: 0.9788 - val_loss: 0.1458 - val_acc: 0.9910\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0589 - acc: 0.9808 - val_loss: 0.1660 - val_acc: 0.9895\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0589 - acc: 0.9809 - val_loss: 0.1382 - val_acc: 0.9914\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0559 - acc: 0.9822 - val_loss: 0.1650 - val_acc: 0.9898\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0548 - acc: 0.9815 - val_loss: 0.1281 - val_acc: 0.9919\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0511 - acc: 0.9837 - val_loss: 0.1406 - val_acc: 0.9912\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0512 - acc: 0.9836 - val_loss: 0.1266 - val_acc: 0.9921\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0510 - acc: 0.9834 - val_loss: 0.1293 - val_acc: 0.9914\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0476 - acc: 0.9844 - val_loss: 0.1305 - val_acc: 0.9919\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0478 - acc: 0.9850 - val_loss: 0.1182 - val_acc: 0.9926\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0462 - acc: 0.9843 - val_loss: 0.1228 - val_acc: 0.9924\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0448 - acc: 0.9848 - val_loss: 0.1343 - val_acc: 0.9917\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0443 - acc: 0.9860 - val_loss: 0.1272 - val_acc: 0.9919\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0458 - acc: 0.9847 - val_loss: 0.1284 - val_acc: 0.9917\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0424 - acc: 0.9860 - val_loss: 0.1262 - val_acc: 0.9921\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0398 - acc: 0.9864 - val_loss: 0.1266 - val_acc: 0.9921\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0414 - acc: 0.9859 - val_loss: 0.1420 - val_acc: 0.9912\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0405 - acc: 0.9864 - val_loss: 0.1075 - val_acc: 0.9933\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0382 - acc: 0.9872 - val_loss: 0.1113 - val_acc: 0.9931\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0385 - acc: 0.9871 - val_loss: 0.1266 - val_acc: 0.9921\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0377 - acc: 0.9874 - val_loss: 0.1010 - val_acc: 0.9936\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0366 - acc: 0.9878 - val_loss: 0.1041 - val_acc: 0.9933\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0356 - acc: 0.9888 - val_loss: 0.1319 - val_acc: 0.9917\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0345 - acc: 0.9881 - val_loss: 0.1080 - val_acc: 0.9931\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0366 - acc: 0.9878 - val_loss: 0.1103 - val_acc: 0.9931\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0350 - acc: 0.9882 - val_loss: 0.1036 - val_acc: 0.9936\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0356 - acc: 0.9881 - val_loss: 0.1026 - val_acc: 0.9936\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0332 - acc: 0.9891 - val_loss: 0.1036 - val_acc: 0.9936\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0332 - acc: 0.9886 - val_loss: 0.1149 - val_acc: 0.9926\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0309 - acc: 0.9895 - val_loss: 0.1163 - val_acc: 0.9924\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.1198 - val_acc: 0.9924\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0311 - acc: 0.9892 - val_loss: 0.1075 - val_acc: 0.9933\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 18s 248ms/step - loss: 0.0310 - acc: 0.9896 - val_loss: 0.0985 - val_acc: 0.9938\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.1151 - val_acc: 0.9929\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0275 - acc: 0.9911 - val_loss: 0.1190 - val_acc: 0.9926\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0284 - acc: 0.9904 - val_loss: 0.1016 - val_acc: 0.9936\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0286 - acc: 0.9904 - val_loss: 0.1156 - val_acc: 0.9926\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0287 - acc: 0.9910 - val_loss: 0.1160 - val_acc: 0.9926\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0292 - acc: 0.9897 - val_loss: 0.1228 - val_acc: 0.9924\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.1242 - val_acc: 0.9921\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0288 - acc: 0.9899 - val_loss: 0.1109 - val_acc: 0.9931\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0263 - acc: 0.9912 - val_loss: 0.1113 - val_acc: 0.9931\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0280 - acc: 0.9905 - val_loss: 0.0959 - val_acc: 0.9940\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0254 - acc: 0.9914 - val_loss: 0.1260 - val_acc: 0.9921\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0264 - acc: 0.9914 - val_loss: 0.1011 - val_acc: 0.9936\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 18s 248ms/step - loss: 0.0268 - acc: 0.9912 - val_loss: 0.1098 - val_acc: 0.9931\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0238 - acc: 0.9922 - val_loss: 0.1144 - val_acc: 0.9929\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0244 - acc: 0.9917 - val_loss: 0.0998 - val_acc: 0.9938\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0230 - acc: 0.9922 - val_loss: 0.1066 - val_acc: 0.9933\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0241 - acc: 0.9916 - val_loss: 0.1113 - val_acc: 0.9931\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0263 - acc: 0.9910 - val_loss: 0.1190 - val_acc: 0.9926\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.0959 - val_acc: 0.9940\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0234 - acc: 0.9920 - val_loss: 0.1113 - val_acc: 0.9931\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0242 - acc: 0.9918 - val_loss: 0.1113 - val_acc: 0.9931\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0214 - acc: 0.9933 - val_loss: 0.1114 - val_acc: 0.9929\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0234 - acc: 0.9920 - val_loss: 0.1243 - val_acc: 0.9921\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.1075 - val_acc: 0.9933\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0236 - acc: 0.9924 - val_loss: 0.1141 - val_acc: 0.9929\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0207 - acc: 0.9933 - val_loss: 0.1090 - val_acc: 0.9931\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0205 - acc: 0.9930 - val_loss: 0.1089 - val_acc: 0.9931\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 18s 250ms/step - loss: 0.0204 - acc: 0.9926 - val_loss: 0.1095 - val_acc: 0.9929\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0223 - acc: 0.9925 - val_loss: 0.1075 - val_acc: 0.9933\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0204 - acc: 0.9930 - val_loss: 0.0998 - val_acc: 0.9938\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0203 - acc: 0.9927 - val_loss: 0.1036 - val_acc: 0.9936\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0193 - acc: 0.9935 - val_loss: 0.0998 - val_acc: 0.9938\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0200 - acc: 0.9932 - val_loss: 0.1144 - val_acc: 0.9924\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.1190 - val_acc: 0.9926\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 18s 248ms/step - loss: 0.0188 - acc: 0.9933 - val_loss: 0.1266 - val_acc: 0.9921\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 18s 248ms/step - loss: 0.0196 - acc: 0.9932 - val_loss: 0.1190 - val_acc: 0.9926\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0174 - acc: 0.9942 - val_loss: 0.1075 - val_acc: 0.9933\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0180 - acc: 0.9939 - val_loss: 0.1190 - val_acc: 0.9926\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0186 - acc: 0.9943 - val_loss: 0.1075 - val_acc: 0.9933\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 18s 248ms/step - loss: 0.0179 - acc: 0.9939 - val_loss: 0.1211 - val_acc: 0.9924\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0176 - acc: 0.9941 - val_loss: 0.1223 - val_acc: 0.9924\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0175 - acc: 0.9939 - val_loss: 0.0953 - val_acc: 0.9940\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0166 - acc: 0.9945 - val_loss: 0.1092 - val_acc: 0.9931\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0189 - acc: 0.9936 - val_loss: 0.1170 - val_acc: 0.9926\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 18s 249ms/step - loss: 0.0165 - acc: 0.9948 - val_loss: 0.1113 - val_acc: 0.9931\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 18s 248ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.1305 - val_acc: 0.9919\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 18s 248ms/step - loss: 0.0173 - acc: 0.9944 - val_loss: 0.1268 - val_acc: 0.9919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LQOgMPKSC8VM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "393635e7-5d8c-4147-b665-961a72243c0e"
      },
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "predictions = model.predict(test, verbose=1)\n",
        "results = np.argmax(predictions,axis = 1)\n",
        "pd.DataFrame({\"ImageId\":list(range(1,len(results)+1)),\n",
        "              \"Label\":results}).to_csv(KAGGLE_SUBMISSION_FILE,\n",
        "                                           index=False,\n",
        "                                           header=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000/28000 [==============================] - 9s 310us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}